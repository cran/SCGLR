%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Introduction to SCGLR}
\documentclass[a4paper]{article}
\usepackage{amsmath}
\usepackage{graphicx,subfig}
\usepackage{url}
%\usepackage[authoryear,round]{natbib}
\usepackage{tabularx}
\usepackage{diagbox}
%\usepackage{draftwatermark}
%\SetWatermarkText{Submitted}
%\SetWatermarkScale{1}
%\usepackage[ruled]{algorithm2e}
\usepackage{url}



\newcommand{\pkg}[1]{{\normalfont\fontseries{b}\selectfont #1}} 
\let\proglang=\textit
\let\code=\texttt 






\title{\pkg{SCGLR} - An R Package for Supervised Component Generalized Linear Regression}

\author{
  Fr\'{e}d\'{e}ric Mortier\thanks{UPR Biens et Services des Ecosyst\`emes Forestiers tropicaux (B\&SEF), D\'epartement Environnements et Soci\'et\'es du CIRAD, Campus International de Baillarguet, TA C-105/D, FR-34398 Montpellier Cedex 5},
  Catherine Trottier\thanks{UFR IV, Universit\'e Paul Val\'ery, Route de Mende, FR-34199 Montpellier Cedex 5}
\thanks{UMR I3M, Equipe Probabilit\'es et Statistique, Place Eug\`ene Bataillon, FR-34095 Montpellier Cedex 5},
  Guillaume Cornu\footnotemark[1]
  and Xavier Bry\footnotemark[3]
}

\begin{document}

\maketitle


<<include=FALSE>>=
library(knitr)
opts_chunk$set(
  concordance=FALSE, fig.path='scglr-',tidy=FALSE,size="small"
)
@

\setkeys{Gin}{width=0.6\textwidth}
<<echo=FALSE>>=
options(width=60,prompt = "R> ", continue = "+  ", useFancyQuotes = FALSE)
@
% 
\paragraph{Summary: \\}
\noindent The objective of this paper is to present an \proglang{R} package, \pkg{SCGLR}, implementing a new  PLS regression approach in the multivariate generalized linear framework. The method allows the joint modeling of  random variables from different exponential family distributions, searching for common PLS-type components. We discuss several of the functions in the package focusing in particular on the two main ones: \code{scglr} and \code{scglrCrossVal}. The former constructs  the components and performs the parameter estimation, while the latter selects the approriate number of components by cross-validation. The package is illustrated on an appropriate ecological dataset through which we aim at predicting the abundance of multiple tree genera  given a large number of geo-referenced environmental variables.\\
\noindent {\it Key words}: Multivariate generalized linear model, partial least squares, Fisher Scoring, \proglang{R}

\section{Introduction}
The classical generalized linear model (GLM), used for modeling random variables from exponential family distributions, suffer from different limitations: (i) it does not allow modeling of more than one outcome at a time; (ii) for want of regularization, it cannot deal with many correlated regressors - whatever relevant causal factors they may represent - and thus requires some preliminary selection of regressors; (iii) the degree of explanatory realism of the model and the robustness of the prediction may be highly influenced by this selection. 

We developed the supervised component generalized linear regression (SCGLR) method to overcome these limitations \cite{bry12,bry13}. SCGLR is a multivariate extension of partial least squares (PLS) regression to the generalized linear framework. It allows the relevant information contained in the data to be summarized in a few common components that can predict, as best as possible,  the multivariate outcomes.  The  method was motivated by ecological applications where there is interest in understanding  how  communities of tree species are structured based on environmental traits. Because  species data can be collected through different measurement processes, the outcomes arise from several types of distributions. For example, some species may just be measured through presence/absence and others through count data (e.g., binomial or Poisson distributions). The originality of the SCGLR approach  is to allow the simultaneous modeling of distributions from exponential family;  Bernoulli, binomial, Gaussian and Poisson distributions can currently be handled in the \pkg{SCGLR} package.
 
SCGLR is based on a multivariate GLM and performs a PLS regression on each step of the GLM estimation algorithm. It uses both the responses (e.g., species abundances) and the regressors to calculate common components. Components are constructed sequentially: the first one maximizes some trade-off between its variance and the goodness of fit of the GLM that takes it as sole regressor (cf below for more details), the second one is its  complement in the space orthogonal to the first component, etc, until we get a set of K complementary and mutually independent components, just as in principal component analysis (PCA). Ultimately, these components are used in a GLM as covariates, allowing them to have specific effects on each response. The optimal number of components on which to base the linear predictors is the one that allows the best prediction in cross-validation. The quality of prediction is assessed through various well-known criteria. 
 
In this paper, we introduce an \proglang{R}-package \cite{scglr} that performs SCGLR. We first  briefly review the mathematical basis of the method, then describe the program's features and usage. We illustrate \pkg{SCGLR} on a dataset built from the CoForChange\footnote{more information on CoForChange is available at \url{http://www.coforchange.eu}} and CoForTips\footnote{and for CoForTips \url{http://www.fordev.ethz.ch/research/active/CoForTips}} databases. It gives the abundance of 27 common tree genera in the tropical moistforest of the Congo-Basin and measurements on 40 geo-referenced environmental variables for one thousand 8 by 8 km plots (observations). Each plot's data were obtained by aggregating  data measured on a variable number of previously sampled 0.5 ha sub-plots. Geo-referenced environmental variables were used to describe the physical factors as well as vegetation characteristics.
 
\section{Description of the SCGLR statistical approach}
Let $Y=\left(y^1,\dots,y^q\right)$  be a matrix of $q$ responses we want to model. For this, regressors are classified into two groups. 
Let $X=\left(x^1,\dots,x^p\right)$ be a matrix whose column-vectors code $p$ regressors (possibly including dummy variables coding nominal covariates). These many regressors contain redundancy and hence there is a specific need for regularisation of the coefficients.
Let also $T$ be a matrix whose column-vectors code additional covariates, which are  to be included as they are without any regularisation.   SCGLR assumes that the $q$ responses are dependent on an unknown number of mutually orthogonal components (linear combinations of the covariates $X$), along with covariates $T$. The components are assumed common to all the responses in that they play some role in the GLM fit of each response. Moreover, the components are designed to stay rather close to the principal directions of the covariates, that is, stray from the noise contained in the group of regressors.

Let $u$ be a $p$-coefficient vector. Just as in PCA, the structural strength of a component $f = Xu$ is measured through its variance under a unit-norm constraint on $u$. The components are determined sequentially. The first component $f^1 = Xu^1$ optimizes a trade-off between the goodness-of-fit of a multivariate GLM  using $f^1$ as common explanatory variable along with $T$, and the variance of $f^1$. To be precise, the Fisher scoring algorithm (FSA) used to estimate the GLM of $Y$ on $<f^1 ,T>$ has been altered in its Generalized Least Squares (GLS) step of the current linearised model  according to two alternative approaches. 
\paragraph{LPLS approach:} the first one corresponds to a Local Partial Least Squares procedure (LPLS) and maximises the criterion:
$$\sum_{k=1}^q||z_k||_{W_k}^2 cos^2_{W_k}(z_k;<Xu,T>) ||Xu||_{W_k}^2$$
where $z_k$ are the working variables in the current linearised model,
\begin{itemize}
\item $||z_k||_{W_k}^2 cos^2_{W_k}(z_k;<Xu,T>)$ is a measure of goodness-of-fit,
\item $||Xu||_{W_k}^2$ is a measure of structural relevance.
\end{itemize}
A Singular Value Decomposition algorithm is used to optimize criterion LPLS.
Taking $f^1$'s variance into account regularises coefficient vector $u^1$, which the standard GLS procedure does not. Covariates in $T$ are considered in the regression step, but not taken into account in component $f^1$. Full details on this method can be found, more formally expressed, in \cite{bry13}.
\paragraph{SR approach:} the second one takes the Structural Relevance (SR) more explicitely into account and maximises the criterion: 
$$\psi (u)^{1-s} \phi (u)^s$$
with $\psi (u)=\sum_{k=1}^q||z_k||_{W_k}^2 cos^2_{W_k}(z_k;<Xu,T>) $ contains the goodness-of-fit measure,
and two options for function $\phi$:\\
\begin{itemize}
  \item Component Variance (CV): $\phi(u)=||Xu||_W^2$
  \item Variable Powered Inertia (VPI): $\phi (u)=\left(\sum_{j=1}^p<Xu|x^j>_W^{2l}\right)^{\frac{1}{l}}$,
when $X$  consists of $p$ standardised numeric variables $x^j$. 
\end{itemize}
Tuning-parameter $l$ allows to draw components towards more or less local variable bundles. Tuning-parameter $s$ weights the structural relevance in the criterion. This criterion is maximised using an Iterated Normed Gradient algorithm. We recommend the second criterion (SR) for being more flexible. Default is VPI.

Once $f^1$ is obtained, then $X$ is deflated on $f^1$, that is, projected onto its orthogonal space, yielding residual predictor matrix $X^1$, and the second component $f^2$ is sought in $X^1$ ($f^2 = X^1 u^2$) according to the same trade-off optimization, but including $f^1$ amongst extra-covariates $T$, from there on. And so forth for higher rank components. So, current component $f^r = X^{r-1} u^r$ is based on the matrix of residuals obtained by projecting the original variables $X$ onto the space orthogonal to all previous components $\{f^1 , ... , f^{r-1}\}$, and the estimation procedure of the linearized model within the modified FSA step takes into account covariates $T \cup \{f^1 , ... , f^{r-1}\}$.

Finally, given some integer $R$, a multivariate GLM of the responses is performed on the set $F^R = \{f^1 , ... , f^R\} $ of the first $R$ components,  along with covariates $T$, yielding a coefficient vector for each response $y_k$, with corresponding linear predictor $\eta_k = F^R \gamma_k + T \delta_k $ ($k=1,\dots,q$). Now, each component $f^r$ can be expressed as a linear combination of the original predictors: $f^r = X v^r$. Hence, in matrix form, we have: $F^R = XV^R$. Thus, we can express each linear predictor as a linear combination of the regressors: $\eta_k = X\beta_k + T \delta_k $ with $\beta_k = V^R \gamma_k$. 

The coefficients $\beta_k$ and $ \delta_k$ can be used in cross-validation to determine the optimal number $R$ of components  in order 
to avoid overfitting. Given the number of components $R$ under trial, the observations are repeatedly partitioned into 2 sub-samples: 
$C$ (for calibration) and $S$ (for testing). On each partition, $C$ is used to calculate the $R$ components, and hence the $\beta$'s 
and $\delta$'s, which in turn are used to predict the expectation of the responses on $S$. An appropriate criterion of predictive power is then calculated (depending on the distribution of the responses) and averaged over all $(C,S)$ partitions considered. Eventually, we consider and  select the value of $R$ yielding  the best performance.

\section{Program description and usage}
\subsection{Main description}
 %% Note: If there is markup in \(sub)section, then it has to be escape as above.
\pkg{SCGLR} is developed using \proglang{R} $\geq 3.0$ version \cite{R}. \pkg{SCGLR}  is a set of \proglang{R} functions illustrated on  a floristic data set, \textit{genus}.  \code{scglr()}  and \code{scglrCrossval()} are the two main high level functions, which are respectively dedicated to fitting the model and selecting the number of components. \code{print()}, \code{summary()} and \code{plot()} methods are also available for the \code{scglr()} function.
% 
% 
<<echo=FALSE>>=
suppressPackageStartupMessages(library("SCGLR"))
@

% <<eval=FALSE>>=
% library("SCGLR")
% @
% 
The call to \code{scglr()} has the following structure:
<<eval=FALSE>>=
results.scglr <- scglr(formula,data,family,K,size,offset,subset,
                       na.action,crit,method)
@
% 
The \textit{formula}, \textit{data}, \textit{family} and \textit{K} arguments are required and \textit{size} must be specified if binomial variables are used. 
The \textit{formula} object of the \textit{Formula} class \cite{Formulapkg}  is composed of two or three terms. The first term describes the dependent variables whereas the second term describes the regressors used to construct components, and  the third term describes additional covariates to be included in the model but not used in the linear combination giving the components. The  first two terms should be separated by a $\sim$ symbol as classical \proglang{R} formula objects, whereas the second and third terms, if any, should be separated by a $|$ symbol.  All the elements in each term are separated by a $+$ sign. The formula can be written out explicitly or provided using the \code{multivariateFormula()} function. For example, if $ny=\left(``y1",``y2"\right)$ contains the names of the dependent variables, $nx=\left(``x1",\dots, ``x5"\right)$ the names of the regressors used to construct the component, and $nz=\left(``z1",``z2", ``z3"\right)$ the names of the additional regressors


% 
<<results='hide',echo=FALSE>>=
ny <- paste("y",1:2,sep="")
nx <-paste("x",1:5,sep="")
nz <- paste("z",1:3,sep="")
@
<<eval=TRUE>>=
myformula <- multivariateFormula(ny,nx,nz)
myformula
@  
The \textit{data} argument is an object of the \textit{data.frame} class. The \textit{family} is a vector of characters describing the family of each  dependent variable. In  \code{SCGLR}, ``bernoulli", ``binomial", ``poisson" or ``gaussian" are allowed. For Poisson outcomes,
the \textit{offset} argument is either a vector or a matrix of size: number of observations $\times$ number of Poisson dependent variables, allowing  a different offset for each dependent variable. If binomial dependent variables are included in the model,  \textit{size} must be specified as a matrix describing the number of trials.  

\vspace{0.3cm}
The output of the \code{scglr} function  is an object of class \pkg{SCGLR} made of: 
\begin{itemize}
\item u: matrix of size: number of regressors $\times$ number of components, contains the component-loadings, i.e., the coefficients of the regressors in the linear combination giving each component.
\item comp: matrix of size : number of statistical units  $\times$ number of components, having the components as column vectors.
\item compr: matrix of size : number of statistical units  $\times$ number of components, having the standardized components as column vectors.
\item gamma: list of length number of dependant variables. Each element is a matrix of coefficients, standard errors, z-values and p-values.
\item beta: matrix of size: number of regressors + 1 (intercept)  $\times$ number of dependent variables, contains the coefficients of the regression on the original regressors $X$.
\item lin.pred: data.frame of size: number of statistical units  $\times$ number of dependent variables, the fitted linear predictor.
\item xFactors: data.frame containing the nominal regressors.
\item xNumeric: data.frame containing the quantitative regressors.
\item inertia: matrix of size: number of components  $\times$ 2, contains the percentage and cumulative percentage of the overall regressors' variance, captured by each component.
\item deviance: vector of length: number of dependent variables, gives the deviance of each $y_k$'s GLM on the components.
\end{itemize}

The \code{print()} method gives the values of inertia and deviance.  \code{summary()} gives inertia, deviance, and three additional tables. The first one contains the square correlations between $X$'s and the components, along with two columns highlighting the plane on which the regressors are best projected and their associated square correlations. The second table presents the square correlations between fitted linear predictors and components, with two more columns corresponding to the plane on which the regressors are best projected and their associated square correlations. These two tables  summarize how well the regressors and the dependent variables, through their linear predictors, are represented on the planes. The third table presents the $\gamma$ values obtained from the GLM; only $\gamma$'s with p-values lower than a given cutoff (default $0.05$) are printed.

\subsection{Plots} 

Several specialized plot commands are available to show the results of \code{scglr()}. They are all based on the \pkg{ggplot2} package developed by Wickham, H. \cite{wickham} and as such can be further customized (i.e., one can add more layers or labels for example).
\begin{itemize} 
\item \code{plot()}: general function to produce various plots from  the \code{scglr()} output by selecting elements to draw. This selection is specified by parameters whose names can be abbreviated (e.g. \textit{pred.col} will be understood as \textit{predictors.color}). Options can be set globally using \code{options("plot.SCGLR")}. It will then provide default values that can be further overriden by giving explicit parameter value.

\item \code{barplot()}: takes an \pkg{SCGLR} object as input and produces a barplot of the inertia per component.

\item \code{pairs()}: takes an \pkg{SCGLR} object and produces an array plot for pairwise combinations  of  components (all components or a selected subset).
\end{itemize}



\subsection{Selecting the number of components}
The appropriate number of components to best predict dependent variables remains unknown and must be selected. We propose a cross-validation approach using different criteria to determine the number of components. The call to the \code{scglrCrossVal()} function shares the  same arguments as the \code{scglr()} function with two additional arguments \textit{nfolds} and \textit{type}:
<<eval=FALSE>>=
scglrCrossVal(formula,data,family,K,nfolds,types,size,
                offset,subset,na.action,crit,method)
@
\textit{nfolds} is the number of subsamples to be used in the cross-validation - default is 5. Although \textit{nfolds} can be as large as the sample size (leave-one-out CV), this is not recommended for large datasets. \textit{type} is the criterion to use for cross-validation. Currently five options are available in a general setting: ``mspe" (Mean Squared Prediction Error), ``likelihood", ``aic", ``bic" and ``aicc". When all dependent variables are Bernoulli, the option ``auc" (area under ROC curve) enables to measure the prediction performance. The output of the procedure is a ($q \times (K+1)$) matrix containing the criterion values for each response variable and each model. The first column corresponds to the model without any component.


\section{Examples}

\subsection{Floristic data set}
We illustrate \pkg{SCGLR} using the data \textit{genus}. This example highlights the use of the  multivariate Poisson count distribution with an offset.

\textit{genus} is a dataset built from the CoForChange database. It gives the abundance of 27 common tree genera in the tropical moistforest of the Congo-Basin and measurements on 40 geo-referenced environmental variables for one thousand 8 by 8 km plots (observations). Data on each plot were obtained by aggregating the data measured on a variable number of previously sampled 0.5 ha sub-plots. The geo-referenced environmental variables were used to describe 16 physical factors pertaining to the description of topography, geology and rainfall and the remaining variables give the vegetation characteristics defined through 16-days enhanced vegetation index (EVI). 


<<>>=
data("genus")
dim(genus)
@

<<>>=
names(genus)
@
We chose to use the covariate ``geology" as an additional factor  not directly used in the component construction because of the demonstrated importance of the geological substrates on the spatial distribution of tree species in the Congo Basin  \cite{fayolle12}. We also used the covariate ``surface" as an offset and we added the product $I(lon * lat)$ as a new covariate. 

<<eval=TRUE>>=
ny <- names(genus)[1:27]
sx <- which(names(genus) %in% c("geology","surface"))
nx <- names(genus)[-c(1:27,sx)] 
family <- rep("poisson",length(ny))
formula <- multivariateFormula(ny,c(nx,"I(lon*lat)"),"geology")
formula
offset <- genus$surface
@

<<eval=TRUE,cache=TRUE>>=
K <- 4
genus.cv <- scglrCrossVal(formula=formula,data=genus,family=family,
                          K=K,nfolds=5,type="mspe",offset=offset,
                          method=methodSR(l=1, s=1/2))
@

Concerning the selection procedure, in order to produce comparable values for possibly very different response variables, we used the following heuristic. For each response and each of the $K+1$ models (one model for each number $K$ of components and one for no component), divide the criterion value by its  median over all the models. Then calculate for each number of components the mean of the standardized values over the different response variables. Alternatively, the mean can be used to normalize  instead of the median.
<<tempo,eval=TRUE>>=
criterion <- t(apply(genus.cv,1,function(x) x/mean(x)))
criterion.mean <- apply(criterion,2,mean) 
K.cv <- which.min(criterion.mean)-1
@
In the expression of \textit{K.cv}, the minus $1$ enables to relabel the output such that it matches the actual number of components used. Plotting \textit{criterion} values (see Figure~\ref{fig:plotCv}) displays the change in the selection criterion as the number of components increases. Here, the \textit{criterion} is minimized for $\Sexpr{K.cv}$ components. We can therefore call \code{scglr()} with $K=\Sexpr{K.cv}$.
<<plotCv, fig.align='center', fig.pos='!ht', fig.cap='Mean Squared Prediction Error (MSPE) as a function of the number of components.'>>=
plot(0:K,criterion.mean, type="l",
     xlab="K, number of components", ylab="Criterion (MSPE)")
Axis(side=1,at=0:K)
abline(v=K.cv,col=2)
@

<<eval=TRUE,cache=TRUE>>=
genus.scglr<-scglr(formula=formula,data=genus,family=family,
                   K=K.cv,size=NULL,offset=offset,
                   method=methodSR(l=1,s=1/2))
@
% <<echo=FALSE,eval=FALSE>>=
% save(genus.cv,genus.scglr,file="data/resTempK15MSPE.rdata")
% @
Printing \textit{genus.scglr}:
<<eval=TRUE>>=
print(genus.scglr)
@
Inertia of the \Sexpr{K.cv} components (see Figure~\ref{fig:barplotScglr}): 

<<barplotScglr, fig.align='center', fig.pos='!ht', fig.cap='Barplot of inertia per component'>>=
barplot(genus.scglr)
@

The  following two commands create the plots in Figure~\ref{fig:samplePlots}. The first one gives a simple correlation plot (see Figure~\ref{fig:samplePlots1}) 

The second correlation plot (see Figure~\ref{fig:samplePlots2}) displays only the linear predictors and covariates whose norms in the selected plane exceed the threshold specified by the "thr" \textit{styles} element.

<<samplePlots, fig.align='center',fig.pos='!ht',fig.cap='Two sample plots',fig.subcap=c('Simple correlation plot','Correlation plot with linear predictors and covariates passing a threshold of $0.8$'),fig.show='hold',out.width='0.49\\linewidth'>>=
plot(genus.scglr)
plot(genus.scglr, threshold=0.8, predictors=TRUE)
@

Finally, we present the \textit{pairs} plot on the planes spanned by components (see Figure~\ref{fig:pairsScglr}): 
<<pairsScglr,fig.align='center', fig.pos='!ht', fig.cap='Correlation plots on planes spanned by components'>>=
pairs(genus.scglr,ncol=2,label.size=0.5) 
@

\section{Conclusion}
The main features of the \proglang{R} package \pkg{SCGLR} have been explained and illustrated in this paper using the data set \textit{genus}  provided with the package. Contrary to  existing  PLS-dedicated packages that can only handle Gaussian data, \pkg{SCGLR} provides  a unified framework to deal with  multivariate outcomes arising from any exponential family distribution. The computational time required to run \code{scglr} depends on the dimension of the problem. Table~\ref{times} provides the mean user times required to run 100 simulations of the \textit{scglr()} algorithm using one component with $p=100$ covariates and a varying number of dependent variables ($q=10$ and $100$) and varying sample sizes ($n=100,1000$ and $10,000$).   These results highlight the  efficiency of the \pkg{SCGLR} package.
\begin{table}
\centering
\begin{tabular}{c|ccc}\hline
\backslashbox{q}{n} &  100   & 1000 & 10000\\\hline
10  &  0.075 & 1.11 & 17.10 \\
100 & 2.942 & 5.644 & 31.60\\ \hline
\end{tabular}
\caption{Mean user times (in seconds)  to calculate one SCGLR component for 10 or 100 dependent variables and 100, 1000 or 10,000 observations\label{times}}
\end{table}


\section{Acknowledgments}
This research  was supported by ITG-SEITA  and was part of the CoForChange project (\url{www.coforchange.eu}), funded by the ERA-Net BiodivERsA, with the national funders ANR (France) and NERC (UK), part of the 2008 BiodivERsA call for research proposals, involving 16 European, African and international partners including a number of timber companies (see the list on the website, \url{http://www.coforchange.eu/partners}), and of the CoForTips project, funded by the ERA-Net BiodivERsA, with the national funders FWF (Austria), BelSPO (Belgium) and ANR (France), part of the 2011-2012 BiodivERsA call for research proposals (\url{http://www.fordev.ethz.ch/research/active/CoForTips}).
\bibliographystyle{plain}
\bibliography{bibScglr}
\end{document}
